{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceMaskDetectionTraining.ipynb",
      "provenance": [],
      "mount_file_id": "10T3sCirl1A7x8StsQvniEDOeMSPEG5Ul",
      "authorship_tag": "ABX9TyMETOxmpgNpW2BBEw7G7N7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanChongder/Image_Processing_And_Face_Mask_Detection/blob/main/FaceMaskDetectionTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_us1N5KrOGhb"
      },
      "source": [
        "Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByoSRj40Nm5R"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# keras is free source deep learning library in python\n",
        "# from this library different layer will be imported\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH-2cPUNOFTX"
      },
      "source": [
        "Loading the CSV File "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzifmEiiY1X7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5e45f4-4934-427f-db9d-0f0de16a768f"
      },
      "source": [
        "# Method to read CSV Files\n",
        "def read_CSV( path ):\n",
        "    try:\n",
        "        file = pd.read_csv( path )\n",
        "        return file\n",
        "    except FileNotFoundError:\n",
        "        print( \"CSV File not found at \" + path )\n",
        "        return None\n",
        "    except Exception:\n",
        "        print(\" Unknown error appeared \")\n",
        "        return None\n",
        "\n",
        "# reading the csv file \n",
        "\n",
        "data_set = read_CSV('drive/MyDrive/FaceMaskDetection/DataSet.csv') \n",
        "#data_set = read_CSV('DataSet.csv') \n",
        "print( data_set.info() ) # checking info of the data set \n",
        "print( data_set.head())  # showing the first ew line of the data set \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1303 entries, 0 to 1302\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   pixels  1303 non-null   object\n",
            " 1   tag     1303 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 20.5+ KB\n",
            "None\n",
            "                                              pixels  tag\n",
            "0  248.0 247.0 246.0 248.0 243.0 187.0 80.0 127.0...    0\n",
            "1  192.0 166.0 118.0 133.0 151.0 143.0 99.0 70.0 ...    0\n",
            "2  87.0 97.0 90.0 74.0 54.0 40.0 38.0 52.0 80.0 7...    0\n",
            "3  250.0 240.0 207.0 240.0 78.0 50.0 87.0 61.0 57...    0\n",
            "4  14.0 7.0 11.0 8.0 18.0 58.0 67.0 80.0 88.0 89....    0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0geaBiaAOm-7"
      },
      "source": [
        "Data Extraction from the CSV file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByQDmIwhOr6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdfe90a-24c2-4eb6-d40c-094ff3ffc4c0"
      },
      "source": [
        "# Addition of data into list from CSV for training and public testing\n",
        "def data_Addition( train_ratio ) :\n",
        "    global x_train , y_train , x_test , y_test , data_set , x_validate , y_validate \n",
        "    mask_px , without_mask = [] , [] \n",
        "    \n",
        "    for row_count,row in data_set.iterrows():\n",
        "\n",
        "        value = row['pixels'].split(' ')                                         # extracting the pixels as a list\n",
        "        value.pop(-1)\n",
        "\n",
        "        try :\n",
        "          \n",
        "          # adding the pixels\n",
        "          mask_px.append(np.array(value,'float32')) if row['tag'] == 0 else  without_mask.append(np.array(value,'float32')) \n",
        "                                               \n",
        "        except:\n",
        "\n",
        "            print(\" Error occurred at row number \" + str(row_count) )\n",
        "            print(\"Data Set in that row is \" + row )\n",
        "\n",
        "\n",
        "    x_validate , y_validate = mask_px[:100] + without_mask[:100] , [0]*100 + [1]*100   # extracting data for validation \n",
        "    mask_px , without_mask = mask_px[100:] , without_mask[100:]                        # removing the data from data set  \n",
        "\n",
        "    # dividing the data into ratio \n",
        "    train_mx  = int(len(mask_px)*(train_ratio/100))                               # with mask \n",
        "    train_wmx = int(len(without_mask)*(train_ratio/100))                          # with out mask \n",
        "\n",
        "    x_train , y_train = mask_px[:train_mx] + without_mask[:train_wmx] , [0]*train_mx+[1]*train_wmx \n",
        "    x_test  , y_test  = mask_px[train_mx:] + without_mask[train_wmx:] , [0]*len(mask_px[train_mx:])+[1]*len(without_mask[train_wmx:])\n",
        "\n",
        "    print( len(x_train) , len(y_train) , len(x_test) , len(y_test) )      \n",
        "\n",
        "# Now we will do training and public testing\n",
        "\n",
        "x_train , y_train = [] , []                                                       # data the will be used for training will added in this two lists\n",
        "x_test , y_test = [] , []                                                         # data that will be used for public testing will be added here\n",
        "x_validate , y_validate = [] , []                                                 # for building the confusion matrix \n",
        "\n",
        "data_Addition( 70 )    # addition of data in the lists for training and testing\n",
        "\n",
        "print( \"Training : \" , len(x_train) , \"Testing : \" , len(x_test) )\n",
        "\n",
        "# checking the lists\n",
        "print( x_train[:2])\n",
        "print( y_train[:2])\n",
        "\n",
        "print(x_train[0].shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "771 771 332 332\n",
            "Training :  771 Testing :  332\n",
            "[array([254., 254., 253., ..., 255., 255., 255.], dtype=float32), array([253., 253., 254., ..., 235., 211., 231.], dtype=float32)]\n",
            "[0, 0]\n",
            "(2304,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pq0SzreMUgb"
      },
      "source": [
        "Convertion to numpy array "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcdETGWsMWad",
        "outputId": "45b28fa6-9513-4fa5-928a-44cacacbb317"
      },
      "source": [
        "# Method to Convert from list to Numpy Arrays\n",
        "def Convert_to_np_Array():\n",
        "    global x_train, x_test, y_test , y_train\n",
        "    # Converting list to numpy Array\n",
        "    x_train = np.array(x_train, 'float32')\n",
        "    y_train = np.array(y_train, 'float32')\n",
        "    x_test = np.array(x_test, 'float32')\n",
        "    y_test = np.array(y_test, 'float32')\n",
        "\n",
        "\n",
        "\n",
        "# As the Keras Module only takes numpy arrays as input\n",
        "# we need to convert this lists into numpy arrays\n",
        "\n",
        "\n",
        "Convert_to_np_Array()\n",
        "print( type(x_train) )  # checking if the type has changed to numpy or not \n",
        "print( y_train )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od_qB62OMc2c"
      },
      "source": [
        "Rescale and reshape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5xjVQ_hMegB",
        "outputId": "25fa793d-68ba-423d-9ea1-16e68f789cea"
      },
      "source": [
        "def Rescale():\n",
        "    # Normalizing the data\n",
        "    # why data normalization is required - https://www.import.io/post/what-is-data-normalization-and-why-is-it-important/\n",
        "    # how it's work - https://www.educative.io/edpresso/data-normalization-in-python\n",
        "    # read Out - https://www.mathsisfun.com/data/standard-deviation.html\n",
        "\n",
        "    global x_train , x_test , y_test , y_train\n",
        "\n",
        "    # we are basically rescaling\n",
        "    x_train -= np.mean(x_train, axis=0)\n",
        "    x_train /= np.std(x_train, axis=0)  # CENTRALIZING THE DATA\n",
        "\n",
        "    x_test -= np.mean(x_test, axis=0)\n",
        "    x_test /= np.std(x_test, axis=0)\n",
        "\n",
        "\n",
        "def Reshape( width , height ):\n",
        "\n",
        "    global x_train , y_train , x_test , y_test\n",
        "\n",
        "    x_train = x_train.reshape(x_train.shape[0], width, height, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], width, height, 1)\n",
        "\n",
        "    print( \"Shape of x \" , x_train.shape )\n",
        "\n",
        "    # WHAT THIS FUNCTION DOES TO_CATEGORICAL\n",
        "    y_train = np_utils.to_categorical(y_train,num_classes=2)\n",
        "    y_test = np_utils.to_categorical(y_test,num_classes=2)\n",
        "    \n",
        "    \n",
        "    print( ' Reshape method is called  ')\n",
        "\n",
        "# Rescalling the data\n",
        "Rescale()\n",
        "\n",
        "# Reshaping the x train and y train in to a one d array\n",
        "Reshape(48,48)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x  (771, 48, 48, 1)\n",
            " Reshape method is called  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBOvEGeqMkUK"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKZulVPaMlZx",
        "outputId": "c5f9e9f8-c61e-4311-f365-46fa0a09c8ce"
      },
      "source": [
        "\n",
        "def Design_CNN():\n",
        "\n",
        "    # The number of epochs is a hyperparameter\n",
        "    # that defines the number times that the learning algorithm will work through the entire training dataset\n",
        "    features =  64\n",
        "    Batch_size = 128\n",
        "    Label = 2\n",
        "    epoch = 50\n",
        "    global  x_train, y_train , x_test , y_test \n",
        "    model = Sequential()\n",
        "\n",
        "    ## Layer 1\n",
        "    # adding layers\n",
        "    # Conv2d is used as the image are in 2d format\n",
        "    # here we are trying extract input\n",
        "    # Relu is a rectifier\n",
        "\n",
        "    # Search Kernal size\n",
        "    model.add(Conv2D(features,kernel_size=(1,1),activation='relu',input_shape=(x_train.shape[1:])))\n",
        "    model.add(Conv2D(features,kernel_size=(3, 3),activation='relu'))\n",
        "\n",
        "    # adding a max pooling 2D layer\n",
        "    # It mainly helps to control over fitting\n",
        "    # can use average pooling layer also\n",
        "    model.add( MaxPool2D(pool_size=(2,2),strides=(2,2)) )\n",
        "\n",
        "    # adding a drop out layer\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ## 2ND layer\n",
        "    model.add(Conv2D(features, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(Conv2D(features, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ## 3RD Layer\n",
        "    model.add(Conv2D(2*features, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(Conv2D(2*features, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # ## 4TH Layer\n",
        "    model.add(Conv2D(2*features, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(Conv2D(2*features, kernel_size=(1, 1), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add( Flatten() )\n",
        "\n",
        "    # adding dense layers\n",
        "    model.add(Dense(2**3 * features, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(2 ** 3 * features, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Adding the final layers\n",
        "    model.add(Dense(Label,activation='softmax')) # Activation is softmax as we want to bind in the 7 labels of 0ptions\n",
        "\n",
        "    model.compile(loss=categorical_crossentropy,optimizer=Adam(),metrics=['accuracy'])\n",
        "    model.fit(x_train,y_train,batch_size=Batch_size,epochs=epoch,verbose=1,validation_data=(x_test,y_test), shuffle=True )\n",
        "\n",
        "    # Saving the model\n",
        "\n",
        "    EmotionDetectJson = model.to_json()\n",
        "    \n",
        "    # drive/MyDrive/FaceMaskDetection/TrainedModel/July11_21/Model2/\n",
        "    # drive/MyDrive/FaceMaskDetection/TrainedModel/July11_21/Model2/\n",
        "    \n",
        "    with open(\"drive/MyDrive/FaceMaskDetection/TrainedModel/July16_21/Model1/fer.json\",\"w\") as file :\n",
        "        file.write(EmotionDetectJson)\n",
        "    model.save_weights(\"drive/MyDrive/FaceMaskDetection/TrainedModel/July16_21/Model1/fer.h5\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Start designing Our CNN\n",
        "\n",
        "# To build the model we will be using sequential Type\n",
        "\n",
        "Design_CNN()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - 2s 142ms/step - loss: 0.6429 - accuracy: 0.6397 - val_loss: 0.5881 - val_accuracy: 0.6476\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5723 - accuracy: 0.7108 - val_loss: 0.5762 - val_accuracy: 0.7078\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.4587 - accuracy: 0.8179 - val_loss: 0.4664 - val_accuracy: 0.8253\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3725 - accuracy: 0.8754 - val_loss: 0.4058 - val_accuracy: 0.8584\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3716 - accuracy: 0.8806 - val_loss: 0.5600 - val_accuracy: 0.6928\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4868 - accuracy: 0.7463 - val_loss: 0.4633 - val_accuracy: 0.8102\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3806 - accuracy: 0.8591 - val_loss: 0.4174 - val_accuracy: 0.8554\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.3829 - accuracy: 0.8848 - val_loss: 0.4138 - val_accuracy: 0.8343\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3550 - accuracy: 0.8668 - val_loss: 0.3540 - val_accuracy: 0.8795\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3085 - accuracy: 0.8815 - val_loss: 0.3500 - val_accuracy: 0.8434\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2826 - accuracy: 0.8926 - val_loss: 0.3370 - val_accuracy: 0.8464\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2879 - accuracy: 0.8838 - val_loss: 0.3836 - val_accuracy: 0.8193\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.3722 - accuracy: 0.8494 - val_loss: 0.3580 - val_accuracy: 0.8464\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3203 - accuracy: 0.8790 - val_loss: 0.2942 - val_accuracy: 0.8735\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2923 - accuracy: 0.8836 - val_loss: 0.2983 - val_accuracy: 0.8825\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2553 - accuracy: 0.8962 - val_loss: 0.2729 - val_accuracy: 0.8554\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2736 - accuracy: 0.8760 - val_loss: 0.2514 - val_accuracy: 0.8765\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2639 - accuracy: 0.8769 - val_loss: 0.3010 - val_accuracy: 0.8223\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3102 - accuracy: 0.8610 - val_loss: 0.2681 - val_accuracy: 0.8554\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2877 - accuracy: 0.8789 - val_loss: 0.2700 - val_accuracy: 0.8554\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2587 - accuracy: 0.8825 - val_loss: 0.2666 - val_accuracy: 0.8554\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2443 - accuracy: 0.8995 - val_loss: 0.2750 - val_accuracy: 0.8494\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2409 - accuracy: 0.8859 - val_loss: 0.2491 - val_accuracy: 0.8494\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2229 - accuracy: 0.8936 - val_loss: 0.2419 - val_accuracy: 0.8554\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2008 - accuracy: 0.9024 - val_loss: 0.2769 - val_accuracy: 0.8434\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3045 - accuracy: 0.8659 - val_loss: 0.2578 - val_accuracy: 0.8554\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2354 - accuracy: 0.8929 - val_loss: 0.2529 - val_accuracy: 0.8464\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2261 - accuracy: 0.8858 - val_loss: 0.2443 - val_accuracy: 0.8404\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2279 - accuracy: 0.8981 - val_loss: 0.2388 - val_accuracy: 0.8524\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2043 - accuracy: 0.8966 - val_loss: 0.2279 - val_accuracy: 0.8494\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2164 - accuracy: 0.8844 - val_loss: 0.2264 - val_accuracy: 0.8464\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.2070 - accuracy: 0.8934 - val_loss: 0.2464 - val_accuracy: 0.8464\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2086 - accuracy: 0.8910 - val_loss: 0.2435 - val_accuracy: 0.8464\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2047 - accuracy: 0.8964 - val_loss: 0.2571 - val_accuracy: 0.8524\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2021 - accuracy: 0.8955 - val_loss: 0.2370 - val_accuracy: 0.8494\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1909 - accuracy: 0.8943 - val_loss: 0.2331 - val_accuracy: 0.9036\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1996 - accuracy: 0.9017 - val_loss: 0.2490 - val_accuracy: 0.8494\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2318 - accuracy: 0.8823 - val_loss: 0.2285 - val_accuracy: 0.8614\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1968 - accuracy: 0.9019 - val_loss: 0.2309 - val_accuracy: 0.8524\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1943 - accuracy: 0.9010 - val_loss: 0.2773 - val_accuracy: 0.8193\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.1987 - accuracy: 0.9062 - val_loss: 0.2498 - val_accuracy: 0.8645\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2044 - accuracy: 0.9075 - val_loss: 0.2674 - val_accuracy: 0.8404\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2099 - accuracy: 0.9067 - val_loss: 0.2347 - val_accuracy: 0.8584\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1917 - accuracy: 0.8983 - val_loss: 0.2360 - val_accuracy: 0.8735\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.1851 - accuracy: 0.9058 - val_loss: 0.2551 - val_accuracy: 0.8283\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.1884 - accuracy: 0.8919 - val_loss: 0.2335 - val_accuracy: 0.8645\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.1854 - accuracy: 0.8985 - val_loss: 0.2238 - val_accuracy: 0.9006\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1777 - accuracy: 0.9072 - val_loss: 0.2288 - val_accuracy: 0.8946\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1642 - accuracy: 0.9170 - val_loss: 0.2503 - val_accuracy: 0.8645\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.1616 - accuracy: 0.9104 - val_loss: 0.2579 - val_accuracy: 0.8614\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}